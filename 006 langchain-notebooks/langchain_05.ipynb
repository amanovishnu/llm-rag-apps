{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import AutoConfig\n",
    "from icecream import ic\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig(search_path='../notes-rag/')\n",
    "\n",
    "GROQ_API_KEY = config(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_TRACING_V2 = config(\"LANGCHAIN_TRACING_V2\")\n",
    "LANGCHAIN_ENDPOINT = config(\"LANGCHAIN_ENDPOINT\")\n",
    "LANGCHAIN_PROJECT = config(\"LANGCHAIN_PROJECT\")\n",
    "lANGCHAIN_API_KEY = config(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"gemma2-9b-it\", api_key=GROQ_API_KEY)\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mano, it's nice to meet you!\n",
      "\n",
      "Being a Chief Data Scientist is a fascinating role. What kind of projects are you currently working on? \n",
      "\n",
      "I'm eager to learn more about your work and how I can be of assistance. Perhaps you have some data science questions or tasks you'd like to discuss?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"Hi, My name is Mano, I am a chief Data Scientist\")\n",
    "print(output_parser.invoke(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [\n",
    "    HumanMessage(content=\"Hi, My name is Mano, I am a chief Data Scientist\"),\n",
    "    AIMessage(content=\"Hi Mano, it's nice to meet you! \\n\\nThat's impressive, Chief Data Scientist is a great role. What kind of projects are you currently working on?  I'm always interested in learning about the latest developments in data science.\\n\"),\n",
    "    HumanMessage(content=\"Hey, what was my name ?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Mano.  ðŸ˜Š  \\n\\nI remember that from our introduction!  How can I help you today?  \\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(model.invoke(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = dict()\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hi Mano, it's nice to meet you! \\n\\nAs a large language model, I'm always interested in learning about people working in exciting fields like data science. What kind of projects are you working on these days?  \\n\\nDo you have any specific questions for me about data science or AI that I could help you with?\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 22, 'total_tokens': 94, 'completion_time': 0.130909091, 'prompt_time': 0.000171169, 'queue_time': 0.01434392, 'total_time': 0.13108026}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-c1cd5e27-2af1-4b7c-9cec-71877e30f05a-0' usage_metadata={'input_tokens': 22, 'output_tokens': 72, 'total_tokens': 94}\n",
      "\n",
      "content='Your name is Mano.  You told me at the beginning of our conversation! ðŸ˜Š \\n\\n\\nIs there anything else I can help you with, Mano?\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 107, 'total_tokens': 141, 'completion_time': 0.061818182, 'prompt_time': 0.003261306, 'queue_time': 0.011381832, 'total_time': 0.065079488}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-da1d1ce9-7637-40f7-bb41-479b509c1f8a-0' usage_metadata={'input_tokens': 107, 'output_tokens': 34, 'total_tokens': 141}\n"
     ]
    }
   ],
   "source": [
    "config={\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat_1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\"Hi, My name is Mano, I am a chief Data Scientist\")\n",
    "], config=config)\n",
    "print(response, end=\"\\n\\n\")\n",
    "\n",
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\"what is my name?\")\n",
    "], config=config)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to know! ðŸ˜Š\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 14, 'total_tokens': 52, 'completion_time': 0.069090909, 'prompt_time': 8.888e-05, 'queue_time': 0.014206630000000001, 'total_time': 0.069179789}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-5cb8bb66-377b-44e1-944a-2585e7c13e9a-0' usage_metadata={'input_tokens': 14, 'output_tokens': 38, 'total_tokens': 52}\n"
     ]
    }
   ],
   "source": [
    "config={\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat_2\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\"what is my name?\")\n",
    "], config=config)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a helpful assistant, answer all of the questions to the best of your ability\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Hua Mulan! It's nice to meet you. \\n\\nI'm happy to answer any questions you have to the best of my ability.  What can I help you with today?  ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 32, 'total_tokens': 79, 'completion_time': 0.085454545, 'prompt_time': 0.000366618, 'queue_time': 0.014005032, 'total_time': 0.085821163}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1f73266f-3c59-4d04-9841-d3b69a5d4d34-0', usage_metadata={'input_tokens': 32, 'output_tokens': 47, 'total_tokens': 79})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"Hi my name is Hua Mulan\")\n",
    "]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello Hua Mulan!  It's nice to meet you.  \\n\\nWhat can I do for you today? I'm ready for any questions you have, big or small.  ðŸ˜Š  \\n\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 32, 'total_tokens': 76, 'completion_time': 0.08, 'prompt_time': 0.000310599, 'queue_time': 0.013343519, 'total_time': 0.080310599}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-034063c4-4c95-470b-b32a-8e965559d1f0-0' usage_metadata={'input_tokens': 32, 'output_tokens': 44, 'total_tokens': 76}\n",
      "\n",
      "content='Your name is Hua Mulan.  You told me yourself when you first introduced yourself!  ðŸ˜„ \\n\\n\\nIs there anything else I can help you with, Mulan?\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 89, 'total_tokens': 125, 'completion_time': 0.065454545, 'prompt_time': 0.0022815, 'queue_time': 0.012104509999999999, 'total_time': 0.067736045}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-73dc532c-c895-4caf-8b44-1a1acc47aa88-0' usage_metadata={'input_tokens': 89, 'output_tokens': 36, 'total_tokens': 125}\n",
      "\n",
      "content='Based on the name Hua Mulan, I would guess that you are female.  \\n\\nIs that correct?  \\n\\n\\n\\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 142, 'total_tokens': 168, 'completion_time': 0.047272727, 'prompt_time': 0.004265851, 'queue_time': 0.009215267, 'total_time': 0.051538578}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-b01b5bb8-6f73-4f98-9cd8-365ec4daa141-0' usage_metadata={'input_tokens': 142, 'output_tokens': 26, 'total_tokens': 168}\n"
     ]
    }
   ],
   "source": [
    "config={\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat_3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = with_message_history.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"Hi my name is Hua Mulan\")\n",
    "]}, config)\n",
    "print(response, end=\"\\n\\n\")\n",
    "\n",
    "response = with_message_history.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"whats my name, AI ?\")\n",
    "]}, config)\n",
    "print(response, end=\"\\n\\n\")\n",
    "\n",
    "response = with_message_history.invoke({\"messages\": [\n",
    "    HumanMessage(content=\"based on my name, guess my gender ?\")\n",
    "]}, config)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a helpful assistant, answer all of the questions to the best of your ability in {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='à°®à±€à°•à± à°¨à°®à°¸à±à°•à°°à°¾à°²à±, à°†à°°à±à°¨à±‹à°²à±à°¡à±! ðŸ˜Š \\n\\nà°¨à±‡à°¨à± à°®à±€à°•à± à°¸à°¹à°¾à°¯à°•à°°à°¿à°—à°¾ à°µà±à°¯à°µà°¹à°°à°¿à°¸à±à°¤à°¾à°¨à±. à°®à±€à°°à± à°à°µà±ˆà°¨à°¾ à°ªà±à°°à°¶à±à°¨à°²à± à°…à°¡à°¿à°—à°¿à°¤à±‡ à°¨à±‡à°¨à± à°¨à°¾ à°¶à°•à±à°¤à°¿ à°‰à°¨à±à°¨à°‚à°¤ à°µà°¿à°§à°‚à°—à°¾ à°œà°µà°¾à°¬à± à°‡à°¸à±à°¤à°¾à°¨à±.  \\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 34, 'total_tokens': 116, 'completion_time': 0.149090909, 'prompt_time': 0.000329029, 'queue_time': 0.014961469, 'total_time': 0.149419938}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-d7a9c8f2-ec9f-4583-874e-d331c2cee746-0' usage_metadata={'input_tokens': 34, 'output_tokens': 82, 'total_tokens': 116}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi my name is Arnold\")],\n",
    "    \"language\": \"telugu\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,  get_session_history, input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='à°¨à±‡à°¨à± à°®à±€à°•à± à°¸à°¹à°¾à°¯à°•à°°à°¿à°—à°¾ à°‰à°‚à°Ÿà°¾à°¨à±, à°®à±€ à°ªà±à°°à°¶à±à°¨à°²à°¨à±à°¨à±€ à°¨à±‡à°¨à± à°¤à±†à°²à±à°—à±à°²à±‹ à°¸à°°à°¿à°—à±à°—à°¾ à°œà°µà°¾à°¬à± à°‡à°¸à±à°¤à°¾à°¨à±. \\n\\nà°¶à°‚à°•à°°à± à°®à°¹à°¦à±‡à°µà°¨à± à°…à°¨à°¿ à°®à±€ à°ªà±‡à°°à± à°…à°¨à±‡à°¦à°¿ à°¨à°¾à°•à± à°¤à±†à°²à°¿à°¸à°¿à°‚à°¦à°¿.  \\n\\nà° à°ªà±à°°à°¶à±à°¨à°²à± à°…à°¡à°¿à°—à°¿à°¤à±‡, à°¨à±‡à°¨à± à°¸à°®à°¾à°§à°¾à°¨à°‚ à°šà±†à°¬à±à°¤à°¾à°¨à±. ðŸ˜Š \\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 37, 'total_tokens': 143, 'completion_time': 0.192727273, 'prompt_time': 0.000309828, 'queue_time': 0.014083942, 'total_time': 0.193037101}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-bc1847a7-3b4b-48ff-b8b6-c5e28da58e9d-0' usage_metadata={'input_tokens': 37, 'output_tokens': 106, 'total_tokens': 143}\n",
      "\n",
      "content='à°®à±€ à°ªà±‡à°°à± à°¶à°‚à°•à°°à± à°®à°¹à°¦à±‡à°µà°¨à±.  \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 155, 'total_tokens': 173, 'completion_time': 0.032727273, 'prompt_time': 0.004882388, 'queue_time': 0.00949018, 'total_time': 0.037609661}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-d9bfad7d-9eed-45b6-837e-190f4ada9243-0' usage_metadata={'input_tokens': 155, 'output_tokens': 18, 'total_tokens': 173}\n",
      "\n",
      "content='à°¨à°¾à°•à± à°®à±€ à°²à°¿à°‚à°—à°‚ à°—à±à°°à°¿à°‚à°šà°¿ à°¤à±†à°²à°¿à°¯à°¦à±.  à°®à±€à°°à± à°¤à°¾à°¨à± à° à°²à°¿à°‚à°—à°‚ à°…à°¨à°¿ à°šà±†à°ªà±à°ªà±à°•à±à°‚à°Ÿà±à°¨à±à°¨à°¾à°°à±‹ à°¨à±‡à°¨à± à°† à°µà°¿à°§à°‚à°—à°¾à°¨à±‡ à°¸à±à°µà±€à°•à°°à°¿à°¸à±à°¤à°¾à°¨à±.  \\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 185, 'total_tokens': 246, 'completion_time': 0.110909091, 'prompt_time': 0.005775755, 'queue_time': 0.009440622999999999, 'total_time': 0.116684846}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-c8edf3f9-b09c-4c85-84df-bc3a9b2dd974-0' usage_metadata={'input_tokens': 185, 'output_tokens': 61, 'total_tokens': 246}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config={\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat_4\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = with_message_history.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi my name is Shankar mahadevan\")],\n",
    "    \"language\": \"telugu\"\n",
    "}, config)\n",
    "print(response, end=\"\\n\\n\")\n",
    "\n",
    "response = with_message_history.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"what is my name ?\")],\n",
    "    \"language\": \"telugu\"\n",
    "}, config)\n",
    "print(response, end=\"\\n\\n\")\n",
    "\n",
    "response = with_message_history.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"whats my gender ?\")],\n",
    "    \"language\": \"telugu\"\n",
    "}, config)\n",
    "print(response, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(max_tokens=100, strategy=\"last\", token_counter=model, include_system=True, allow_partial=False, start_on=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi, i am bob', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi bob', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='i like vanilla icecream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi, i am bob\"),\n",
    "    AIMessage(content=\"Hi bob\"),\n",
    "    HumanMessage(content=\"i like vanilla icecream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem\"),\n",
    "    HumanMessage(content=\"having fun ?\"),\n",
    "    AIMessage(content=\"yes\")\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='à°®à±€à°°à± à°µà±‡à°¨à°¿à°² ICE CREAM à°‡à°·à±à°Ÿà°ªà°¡à°¤à°¾à°°à±. ðŸ¦  \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 119, 'total_tokens': 141, 'completion_time': 0.04, 'prompt_time': 0.003539974, 'queue_time': 0.011073104, 'total_time': 0.043539974}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-bf4b2f77-ec00-4360-b284-de97e244415d-0' usage_metadata={'input_tokens': 119, 'output_tokens': 22, 'total_tokens': 141}\n"
     ]
    }
   ],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(messages= itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"what ice cream do i like ?\")],\n",
    "    \"language\": \"telugu\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,  get_session_history, input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m config\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     }\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mwith_message_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhat math problem did i ask for ?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlanguage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtelugu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(response, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m response \u001b[38;5;241m=\u001b[39m with_message_history\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo i like ice cream ?\u001b[39m\u001b[38;5;124m\"\u001b[39m)],\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtelugu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m }, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/passthrough.py:494\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    491\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    493\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1927\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1924\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1925\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1926\u001b[0m         Output,\n\u001b[0;32m-> 1927\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1930\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1935\u001b[0m     )\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1937\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/passthrough.py:481\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    474\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m    477\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m--> 481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    486\u001b[0m     }\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3722\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3719\u001b[0m     \u001b[38;5;66;03m# copy to avoid issues from the caller mutating the steps during invoke()\u001b[39;00m\n\u001b[1;32m   3720\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps__)\n\u001b[0;32m-> 3722\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3723\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3724\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3725\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3726\u001b[0m         ]\n\u001b[1;32m   3727\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/contextlib.py:142\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/site-packages/langchain_core/runnables/config.py:550\u001b[0m, in \u001b[0;36mget_executor_for_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get an executor for a config.\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    Generator[Executor, None, None]: The executor.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    549\u001b[0m config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextThreadPoolExecutor(\n\u001b[1;32m    551\u001b[0m     max_workers\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_concurrency\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m executor\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/threading.py:1118\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m-> 1118\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39mlocked():\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;66;03m# bpo-45274: lock.acquire() acquired the lock, but the function\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m         \u001b[38;5;66;03m# was interrupted with an exception before reaching the\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;66;03m# lock.release(). It can happen if a signal handler raises an\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# exception, like CTRL+C which raises KeyboardInterrupt.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/threading.py:1053\u001b[0m, in \u001b[0;36mThread._stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdaemon:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _shutdown_locks_lock:\n\u001b[1;32m   1052\u001b[0m         \u001b[38;5;66;03m# Remove our lock and other released locks from _shutdown_locks\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m         \u001b[43m_maintain_shutdown_locks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/threading.py:810\u001b[0m, in \u001b[0;36m_maintain_shutdown_locks\u001b[0;34m()\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;124;03mDrop any shutdown locks that don't correspond to running threads anymore.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03mThis must be called with _shutdown_locks_lock acquired.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# If a lock was released, the corresponding thread has exited\u001b[39;00m\n\u001b[0;32m--> 810\u001b[0m to_remove \u001b[38;5;241m=\u001b[39m [lock \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m _shutdown_locks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lock\u001b[38;5;241m.\u001b[39mlocked()]\n\u001b[1;32m    811\u001b[0m _shutdown_locks\u001b[38;5;241m.\u001b[39mdifference_update(to_remove)\n",
      "File \u001b[0;32m~/miniconda3/envs/ragEnv/lib/python3.10/threading.py:810\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;124;03mDrop any shutdown locks that don't correspond to running threads anymore.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03mThis must be called with _shutdown_locks_lock acquired.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# If a lock was released, the corresponding thread has exited\u001b[39;00m\n\u001b[0;32m--> 810\u001b[0m to_remove \u001b[38;5;241m=\u001b[39m [lock \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m _shutdown_locks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lock\u001b[38;5;241m.\u001b[39mlocked()]\n\u001b[1;32m    811\u001b[0m _shutdown_locks\u001b[38;5;241m.\u001b[39mdifference_update(to_remove)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config={\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat_5\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = with_message_history.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"what math problem did i ask for ?\")],\n",
    "    \"language\": \"telugu\"\n",
    "}, config)\n",
    "print(response, end=\"\\n\\n\")\n",
    "\n",
    "response = with_message_history.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"do i like ice cream ?\")],\n",
    "    \"language\": \"telugu\"\n",
    "}, config)\n",
    "print(response, end=\"\\n\\n\")\n",
    "\n",
    "response = with_message_history.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"whats my gender ?\")],\n",
    "    \"language\": \"telugu\"\n",
    "}, config)\n",
    "print(response, end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
